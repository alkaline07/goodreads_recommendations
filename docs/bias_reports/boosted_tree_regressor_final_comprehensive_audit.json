{
  "audit_metadata": {
    "model_name": "boosted_tree_regressor_final",
    "timestamp": "2025-12-10T04:17:05.941227",
    "predictions_table": "recommendation-system-475301.books.boosted_tree_rating_predictions",
    "debiased_table": "recommendation-system-475301.books.boosted_tree_regressor_final_rating_predictions_debiased"
  },
  "bias_detection": {
    "timestamp": "2025-12-10T04:17:09.766232",
    "total_slices_analyzed": 23,
    "disparities_found": 2,
    "high_risk_slices": 1,
    "recommendations": [
      "HIGH PRIORITY: 1 dimensions show severe performance disparities. Dimensions: Rating Range",
      "MEDIUM PRIORITY: 1 dimensions show moderate disparities. Dimensions: Book Era",
      "Target these high-error slices for mitigation: Rating Range=Medium (3-4) (MAE: 3.132)",
      "Rating Range: Consider re-weighting training data or adjusting decision thresholds to balance performance across 2 groups"
    ]
  },
  "mitigation_applied": {
    "techniques": [
      "prediction_shrinkage"
    ],
    "results": [
      {
        "technique": "prediction_shrinkage",
        "output_table": "recommendation-system-475301.books.boosted_tree_regressor_final_rating_predictions_debiased",
        "improvements": {
          "mae_change": 6.73008280379495,
          "disparity_reduction": "See validation step"
        }
      }
    ]
  },
  "validation": {
    "timestamp": "2025-12-10T04:17:15.176347",
    "techniques_applied": [
      "prediction_shrinkage"
    ],
    "effectiveness": {
      "prediction_shrinkage": {
        "improvements": {
          "mae_change": 6.73008280379495,
          "disparity_reduction": "See validation step"
        },
        "output_table": "recommendation-system-475301.books.boosted_tree_regressor_final_rating_predictions_debiased",
        "post_mitigation_disparities": [
          {
            "dimension": "Book Era",
            "severity": "medium",
            "mae_range": 0.29285836514098057,
            "mae_cv": 0.2053045410646213,
            "recommendation": "Significant performance disparity detected in Book Era. Consider bias mitigation."
          },
          {
            "dimension": "Rating Range",
            "severity": "high",
            "mae_range": 2.737671439573546,
            "mae_cv": 0.738901542006349,
            "recommendation": "Significant performance disparity detected in Rating Range. Consider bias mitigation."
          }
        ]
      }
    }
  },
  "executive_summary": {
    "bias_detected": true,
    "severity": "high",
    "dimensions_with_bias": [
      "Book Era",
      "Rating Range"
    ],
    "mitigation_applied": true,
    "overall_status": "MITIGATED"
  }
}